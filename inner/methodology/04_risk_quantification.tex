\subsection{Risk Prioritization Approach}
\label{sec:risk_quantification}

We prioritize threats using a risk scoring approach that combines \textbf{Likelihood (L)}, \textbf{Impact (I)}, and \textbf{Detectability (D)} on 1--5 scales. The unified formula accounts for detectability as a risk modifier, recognizing that harder-to-detect threats pose greater risk. This approach balances traditional risk management principles with the unique challenges of blockchain security.

\subsubsection{Unified Risk Score}
Where a single numeric priority is helpful, we use the unified risk score formula:
\begin{equation}
    \text{Risk Score} = (w_L \times L) + (w_I \times I) - (w_D \times D)
\end{equation}
with default weights $w_L=0.4$, $w_I=0.5$, $w_D=0.1$ to balance impact and likelihood while accounting for detectability as a risk modifier.

\paragraph{Methodological backing} Subtracting detectability is consistent with FMEA-style Risk Priority Number schemes, where harder-to-detect failures increase risk (inverse detectability) \cite{WestgardDetectability,PQRI2015FMEA}. Using a weighted linear combination is standard in cybersecurity risk scoring (e.g., OWASP Risk Rating; ISACA enhanced risk formula; NIST-inspired programmatic scoring) \cite{OWASPRiskRating,ISACA2014EnhancedRisk,ZengRCNIST}. Our impact-centric weighting reflects asymmetric loss considerations common in enterprise risk. Calibration is supported by established practices such as sensitivity analysis and expert elicitation (FAIR calibrated estimation), with optional Monte Carlo/Expected Monetary Value checks for robustness \cite{FAIRCalibratedEstimation,RosemetQRA}.

\subsubsection{Weight Rationale}
The weights are selected to reflect established enterprise risk management principles where the magnitude of potential loss is the primary driver of priority. The assignment of $w_I=0.5$, $w_L=0.4$, and $w_D=0.1$ creates a balanced model that accounts for detectability as a risk modifier, ensuring that high-impact, low-likelihood "black swan" events are not unduly minimized in prioritization while recognizing that harder-to-detect threats pose greater risk. This aligns with frameworks where impact asymmetries and detection challenges are key considerations. While these weights are adaptable, they provide a stable baseline for triage. Future work could pursue formal weight calibration through expert elicitation methods (e.g., Delphi) on the incident corpus.

This weighting scheme aligns with industry best practices and reflects the asymmetric nature of blockchain security threats.

\subsubsection{Scoring Criteria}
\textbf{Likelihood (L) Scale:}
\begin{itemize}
    \item \textbf{1 (Very Low):} Theoretical attack, no known instances
    \item \textbf{2 (Low):} Rare occurrences, significant technical barriers
    \item \textbf{3 (Medium):} Occasional incidents, moderate technical requirements
    \item \textbf{4 (High):} Frequent occurrences, minimal technical barriers
    \item \textbf{5 (Very High):} Widespread exploitation, automated tools available
\end{itemize}

\textbf{Impact (I) Scale:}
\begin{itemize}
    \item \textbf{1 (Minimal):} < \$100K loss, no service disruption
    \item \textbf{2 (Minor):} \$100K-\$1M loss, temporary service issues
    \item \textbf{3 (Moderate):} \$1M-\$10M loss, significant service disruption
    \item \textbf{4 (Major):} \$10M-\$100M loss, protocol failure
    \item \textbf{5 (Critical):} > \$100M loss, systemic failure
\end{itemize}

\textbf{Detectability (D) Scale:}
\begin{itemize}
    \item \textbf{1 (Very Easy):} Immediate detection, clear indicators
    \item \textbf{2 (Easy):} Quick detection, obvious symptoms
    \item \textbf{3 (Moderate):} Detectable with monitoring, some ambiguity
    \item \textbf{4 (Difficult):} Requires specialized tools, subtle indicators
    \item \textbf{5 (Very Difficult):} Stealth attacks, minimal indicators
\end{itemize}

\subsubsection{Sensitivity Analysis}
We examine ranking stability across reasonable $w_L/w_I/w_D$ variations and confirm that categories with high impact remain top priorities while accounting for detectability effects. Full quantitative evaluation (expert calibration, historical consistency checks) is future work \cite{FAIRCalibratedEstimation,ADICorrelation}.

\subsection{Risk Prioritization Approach}
\label{sec:risk_quantification}

We prioritize threats primarily by \textbf{Likelihood (L)} and \textbf{Impact (I)} on 1--5 scales. \textbf{Detectability (D)} is treated as a \textit{separate control-gap attribute} that influences monitoring and response planning rather than being combined arithmetically with L/I. This aligns with NIST/ISO practice, where detect functions mitigate but do not reduce inherent risk.

\subsubsection{Composite Score (L/I only)}
Where a single numeric priority is helpful, we use:
\begin{equation}
    \text{Composite} = (w_L \times L) + (w_I \times I),\quad w_L + w_I = 1
\end{equation}
with default weights $w_L=0.4$, $w_I=0.6$ to emphasize impact while preserving likelihood contributions. Detectability is reported alongside this composite.

\subsubsection{Weight Rationale}
The weights are selected to reflect established enterprise risk management principles where the magnitude of potential loss is the primary driver of priority. The assignment of $w_I=0.6$ and $w_L=0.4$ creates an \textit{impact-forward} model, ensuring that high-impact, low-likelihood "black swan" events are not unduly minimized in prioritization. This aligns with frameworks where impact asymmetries are a key consideration. While these weights are adaptable, they provide a stable baseline for triage. Future work could pursue formal weight calibration through expert elicitation methods (e.g., Delphi) on the incident corpus.

This weighting scheme aligns with industry best practices and reflects the asymmetric nature of blockchain security threats.

\subsubsection{Scoring Criteria}
\textbf{Likelihood (L) Scale:}
\begin{itemize}
    \item \textbf{1 (Very Low):} Theoretical attack, no known instances
    \item \textbf{2 (Low):} Rare occurrences, significant technical barriers
    \item \textbf{3 (Medium):} Occasional incidents, moderate technical requirements
    \item \textbf{4 (High):} Frequent occurrences, minimal technical barriers
    \item \textbf{5 (Very High):} Widespread exploitation, automated tools available
\end{itemize}

\textbf{Impact (I) Scale:}
\begin{itemize}
    \item \textbf{1 (Minimal):} < \$100K loss, no service disruption
    \item \textbf{2 (Minor):} \$100K-\$1M loss, temporary service issues
    \item \textbf{3 (Moderate):} \$1M-\$10M loss, significant service disruption
    \item \textbf{4 (Major):} \$10M-\$100M loss, protocol failure
    \item \textbf{5 (Critical):} > \$100M loss, systemic failure
\end{itemize}

\textbf{Detectability (D) Scale:}
\begin{itemize}
    \item \textbf{1 (Very Easy):} Immediate detection, clear indicators
    \item \textbf{2 (Easy):} Quick detection, obvious symptoms
    \item \textbf{3 (Moderate):} Detectable with monitoring, some ambiguity
    \item \textbf{4 (Difficult):} Requires specialized tools, subtle indicators
    \item \textbf{5 (Very Difficult):} Stealth attacks, minimal indicators
\end{itemize}

\subsubsection{Sensitivity Analysis}
We examine ranking stability across reasonable $w_L/w_I$ variations and confirm that categories with high impact remain top priorities. Full quantitative evaluation is future work.
